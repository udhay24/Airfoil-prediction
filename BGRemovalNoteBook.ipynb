{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "BGRemovalNoteBook.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udhay24/Airfoil-prediction/blob/master/BGRemovalNoteBook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqvrVnnFu4jD",
        "outputId": "d674acbf-744c-486e-c820-b4fc56256b58"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install opencv-python\n",
        "!pip install Pillow\n",
        "!pip install tqdm\n",
        "!pip install scikit-image\n",
        "!pip install numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (54.1.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.0+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchvision) (3.7.4.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.16.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.0.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.5)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.19.0->scikit-image) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzfO6EeIyt5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63304499-3721-4a20-c1d6-9e8671f8a787"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UvCiDY404HB",
        "outputId": "3af85620-f534-464f-e91b-10837dec8a29"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8K0qsfFxh8P"
      },
      "source": [
        "# data loader\n",
        "from __future__ import print_function, division\n",
        "import glob\n",
        "import torch\n",
        "from skimage import io, transform, color\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from PIL import Image\n",
        "\n",
        "#==========================dataset load==========================\n",
        "class RescaleT(object):\n",
        "\n",
        "\tdef __init__(self,output_size):\n",
        "\t\tassert isinstance(output_size,(int,tuple))\n",
        "\t\tself.output_size = output_size\n",
        "\n",
        "\tdef __call__(self,sample):\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'],sample['label']\n",
        "\n",
        "\t\th, w = image.shape[:2]\n",
        "\n",
        "\t\tif isinstance(self.output_size,int):\n",
        "\t\t\tif h > w:\n",
        "\t\t\t\tnew_h, new_w = self.output_size*h/w,self.output_size\n",
        "\t\t\telse:\n",
        "\t\t\t\tnew_h, new_w = self.output_size,self.output_size*w/h\n",
        "\t\telse:\n",
        "\t\t\tnew_h, new_w = self.output_size\n",
        "\n",
        "\t\tnew_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "\t\t# #resize the image to new_h x new_w and convert image from range [0,255] to [0,1]\n",
        "\t\t# img = transform.resize(image,(new_h,new_w),mode='constant')\n",
        "\t\t# lbl = transform.resize(label,(new_h,new_w),mode='constant', order=0, preserve_range=True)\n",
        "\n",
        "\t\timg = transform.resize(image,(self.output_size,self.output_size),mode='constant')\n",
        "\t\tlbl = transform.resize(label,(self.output_size,self.output_size),mode='constant', order=0, preserve_range=True)\n",
        "\n",
        "\t\treturn {'imidx':imidx, 'image':img,'label':lbl}\n",
        "\n",
        "class Rescale(object):\n",
        "\n",
        "\tdef __init__(self,output_size):\n",
        "\t\tassert isinstance(output_size,(int,tuple))\n",
        "\t\tself.output_size = output_size\n",
        "\n",
        "\tdef __call__(self,sample):\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'],sample['label']\n",
        "\n",
        "\t\tif random.random() >= 0.5:\n",
        "\t\t\timage = image[::-1]\n",
        "\t\t\tlabel = label[::-1]\n",
        "\n",
        "\t\th, w = image.shape[:2]\n",
        "\n",
        "\t\tif isinstance(self.output_size,int):\n",
        "\t\t\tif h > w:\n",
        "\t\t\t\tnew_h, new_w = self.output_size*h/w,self.output_size\n",
        "\t\t\telse:\n",
        "\t\t\t\tnew_h, new_w = self.output_size,self.output_size*w/h\n",
        "\t\telse:\n",
        "\t\t\tnew_h, new_w = self.output_size\n",
        "\n",
        "\t\tnew_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "\t\t# #resize the image to new_h x new_w and convert image from range [0,255] to [0,1]\n",
        "\t\timg = transform.resize(image,(new_h,new_w),mode='constant')\n",
        "\t\tlbl = transform.resize(label,(new_h,new_w),mode='constant', order=0, preserve_range=True)\n",
        "\n",
        "\t\treturn {'imidx':imidx, 'image':img,'label':lbl}\n",
        "\n",
        "class RandomCrop(object):\n",
        "\n",
        "\tdef __init__(self,output_size):\n",
        "\t\tassert isinstance(output_size, (int, tuple))\n",
        "\t\tif isinstance(output_size, int):\n",
        "\t\t\tself.output_size = (output_size, output_size)\n",
        "\t\telse:\n",
        "\t\t\tassert len(output_size) == 2\n",
        "\t\t\tself.output_size = output_size\n",
        "\tdef __call__(self,sample):\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'], sample['label']\n",
        "\n",
        "\t\tif random.random() >= 0.5:\n",
        "\t\t\timage = image[::-1]\n",
        "\t\t\tlabel = label[::-1]\n",
        "\n",
        "\t\th, w = image.shape[:2]\n",
        "\t\tnew_h, new_w = self.output_size\n",
        "\n",
        "\t\ttop = np.random.randint(0, h - new_h)\n",
        "\t\tleft = np.random.randint(0, w - new_w)\n",
        "\n",
        "\t\timage = image[top: top + new_h, left: left + new_w]\n",
        "\t\tlabel = label[top: top + new_h, left: left + new_w]\n",
        "\n",
        "\t\treturn {'imidx':imidx,'image':image, 'label':label}\n",
        "\n",
        "class ToTensor(object):\n",
        "\t\"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "\tdef __call__(self, sample):\n",
        "\n",
        "\t\timidx, image, label = sample['imidx'], sample['image'], sample['label']\n",
        "\n",
        "\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\t\ttmpLbl = np.zeros(label.shape)\n",
        "\n",
        "\t\timage = image/np.max(image)\n",
        "\t\tif(np.max(label)<1e-6):\n",
        "\t\t\tlabel = label\n",
        "\t\telse:\n",
        "\t\t\tlabel = label/np.max(label)\n",
        "\n",
        "\t\tif image.shape[2]==1:\n",
        "\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\ttmpImg[:,:,1] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\ttmpImg[:,:,2] = (image[:,:,0]-0.485)/0.229\n",
        "\t\telse:\n",
        "\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\ttmpImg[:,:,1] = (image[:,:,1]-0.456)/0.224\n",
        "\t\t\ttmpImg[:,:,2] = (image[:,:,2]-0.406)/0.225\n",
        "\n",
        "\t\ttmpLbl[:,:,0] = label[:,:,0]\n",
        "\n",
        "\t\t# change the r,g,b to b,r,g from [0,255] to [0,1]\n",
        "\t\t#transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
        "\t\ttmpImg = tmpImg.transpose((2, 0, 1))\n",
        "\t\ttmpLbl = label.transpose((2, 0, 1))\n",
        "\n",
        "\t\treturn {'imidx':torch.from_numpy(imidx), 'image': torch.from_numpy(tmpImg), 'label': torch.from_numpy(tmpLbl)}\n",
        "\n",
        "class ToTensorLab(object):\n",
        "\t\"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\tdef __init__(self,flag=0):\n",
        "\t\tself.flag = flag\n",
        "\n",
        "\tdef __call__(self, sample):\n",
        "\n",
        "\t\timidx, image, label =sample['imidx'], sample['image'], sample['label']\n",
        "\n",
        "\t\ttmpLbl = np.zeros(label.shape)\n",
        "\n",
        "\t\tif(np.max(label)<1e-6):\n",
        "\t\t\tlabel = label\n",
        "\t\telse:\n",
        "\t\t\tlabel = label/np.max(label)\n",
        "\n",
        "\t\t# change the color space\n",
        "\t\tif self.flag == 2: # with rgb and Lab colors\n",
        "\t\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],6))\n",
        "\t\t\ttmpImgt = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\t\t\tif image.shape[2]==1:\n",
        "\t\t\t\ttmpImgt[:,:,0] = image[:,:,0]\n",
        "\t\t\t\ttmpImgt[:,:,1] = image[:,:,0]\n",
        "\t\t\t\ttmpImgt[:,:,2] = image[:,:,0]\n",
        "\t\t\telse:\n",
        "\t\t\t\ttmpImgt = image\n",
        "\t\t\ttmpImgtl = color.rgb2lab(tmpImgt)\n",
        "\n",
        "\t\t\t# nomalize image to range [0,1]\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImgt[:,:,0]-np.min(tmpImgt[:,:,0]))/(np.max(tmpImgt[:,:,0])-np.min(tmpImgt[:,:,0]))\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImgt[:,:,1]-np.min(tmpImgt[:,:,1]))/(np.max(tmpImgt[:,:,1])-np.min(tmpImgt[:,:,1]))\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImgt[:,:,2]-np.min(tmpImgt[:,:,2]))/(np.max(tmpImgt[:,:,2])-np.min(tmpImgt[:,:,2]))\n",
        "\t\t\ttmpImg[:,:,3] = (tmpImgtl[:,:,0]-np.min(tmpImgtl[:,:,0]))/(np.max(tmpImgtl[:,:,0])-np.min(tmpImgtl[:,:,0]))\n",
        "\t\t\ttmpImg[:,:,4] = (tmpImgtl[:,:,1]-np.min(tmpImgtl[:,:,1]))/(np.max(tmpImgtl[:,:,1])-np.min(tmpImgtl[:,:,1]))\n",
        "\t\t\ttmpImg[:,:,5] = (tmpImgtl[:,:,2]-np.min(tmpImgtl[:,:,2]))/(np.max(tmpImgtl[:,:,2])-np.min(tmpImgtl[:,:,2]))\n",
        "\n",
        "\t\t\t# tmpImg = tmpImg/(np.max(tmpImg)-np.min(tmpImg))\n",
        "\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImg[:,:,0]-np.mean(tmpImg[:,:,0]))/np.std(tmpImg[:,:,0])\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImg[:,:,1]-np.mean(tmpImg[:,:,1]))/np.std(tmpImg[:,:,1])\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImg[:,:,2]-np.mean(tmpImg[:,:,2]))/np.std(tmpImg[:,:,2])\n",
        "\t\t\ttmpImg[:,:,3] = (tmpImg[:,:,3]-np.mean(tmpImg[:,:,3]))/np.std(tmpImg[:,:,3])\n",
        "\t\t\ttmpImg[:,:,4] = (tmpImg[:,:,4]-np.mean(tmpImg[:,:,4]))/np.std(tmpImg[:,:,4])\n",
        "\t\t\ttmpImg[:,:,5] = (tmpImg[:,:,5]-np.mean(tmpImg[:,:,5]))/np.std(tmpImg[:,:,5])\n",
        "\n",
        "\t\telif self.flag == 1: #with Lab color\n",
        "\t\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\n",
        "\t\t\tif image.shape[2]==1:\n",
        "\t\t\t\ttmpImg[:,:,0] = image[:,:,0]\n",
        "\t\t\t\ttmpImg[:,:,1] = image[:,:,0]\n",
        "\t\t\t\ttmpImg[:,:,2] = image[:,:,0]\n",
        "\t\t\telse:\n",
        "\t\t\t\ttmpImg = image\n",
        "\n",
        "\t\t\ttmpImg = color.rgb2lab(tmpImg)\n",
        "\n",
        "\t\t\t# tmpImg = tmpImg/(np.max(tmpImg)-np.min(tmpImg))\n",
        "\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImg[:,:,0]-np.min(tmpImg[:,:,0]))/(np.max(tmpImg[:,:,0])-np.min(tmpImg[:,:,0]))\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImg[:,:,1]-np.min(tmpImg[:,:,1]))/(np.max(tmpImg[:,:,1])-np.min(tmpImg[:,:,1]))\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImg[:,:,2]-np.min(tmpImg[:,:,2]))/(np.max(tmpImg[:,:,2])-np.min(tmpImg[:,:,2]))\n",
        "\n",
        "\t\t\ttmpImg[:,:,0] = (tmpImg[:,:,0]-np.mean(tmpImg[:,:,0]))/np.std(tmpImg[:,:,0])\n",
        "\t\t\ttmpImg[:,:,1] = (tmpImg[:,:,1]-np.mean(tmpImg[:,:,1]))/np.std(tmpImg[:,:,1])\n",
        "\t\t\ttmpImg[:,:,2] = (tmpImg[:,:,2]-np.mean(tmpImg[:,:,2]))/np.std(tmpImg[:,:,2])\n",
        "\n",
        "\t\telse: # with rgb color\n",
        "\t\t\ttmpImg = np.zeros((image.shape[0],image.shape[1],3))\n",
        "\t\t\timage = image/np.max(image)\n",
        "\t\t\tif image.shape[2]==1:\n",
        "\t\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\t\ttmpImg[:,:,1] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\t\ttmpImg[:,:,2] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\telse:\n",
        "\t\t\t\ttmpImg[:,:,0] = (image[:,:,0]-0.485)/0.229\n",
        "\t\t\t\ttmpImg[:,:,1] = (image[:,:,1]-0.456)/0.224\n",
        "\t\t\t\ttmpImg[:,:,2] = (image[:,:,2]-0.406)/0.225\n",
        "\n",
        "\t\ttmpLbl[:,:,0] = label[:,:,0]\n",
        "\n",
        "\t\t# change the r,g,b to b,r,g from [0,255] to [0,1]\n",
        "\t\t#transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
        "\t\ttmpImg = tmpImg.transpose((2, 0, 1))\n",
        "\t\ttmpLbl = label.transpose((2, 0, 1))\n",
        "\n",
        "\t\treturn {'imidx':torch.from_numpy(imidx), 'image': torch.from_numpy(tmpImg), 'label': torch.from_numpy(tmpLbl)}\n",
        "\n",
        "class SalObjDataset(Dataset):\n",
        "\tdef __init__(self,img_name_list,lbl_name_list,transform=None):\n",
        "\t\t# self.root_dir = root_dir\n",
        "\t\t# self.image_name_list = glob.glob(image_dir+'*.png')\n",
        "\t\t# self.label_name_list = glob.glob(label_dir+'*.png')\n",
        "\t\tself.image_name_list = img_name_list\n",
        "\t\tself.label_name_list = lbl_name_list\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.image_name_list)\n",
        "\n",
        "\tdef __getitem__(self,idx):\n",
        "\n",
        "\t\t# image = Image.open(self.image_name_list[idx])#io.imread(self.image_name_list[idx])\n",
        "\t\t# label = Image.open(self.label_name_list[idx])#io.imread(self.label_name_list[idx])\n",
        "\n",
        "\t\timage = io.imread(self.image_name_list[idx])\n",
        "\t\timname = self.image_name_list[idx]\n",
        "\t\timidx = np.array([idx])\n",
        "\n",
        "\t\tif(0==len(self.label_name_list)): #if no pixel wise label are provided? (Eshwar comment)\n",
        "\t\t\tlabel_3 = np.zeros(image.shape)\n",
        "\t\telse:\n",
        "\t\t\tlabel_3 = io.imread(self.label_name_list[idx])\n",
        "\n",
        "\t\tlabel = np.zeros(label_3.shape[0:2])\n",
        "\t\tif(3==len(label_3.shape)):\n",
        "\t\t\tlabel = label_3[:,:,0]\n",
        "\t\telif(2==len(label_3.shape)):\n",
        "\t\t\tlabel = label_3\n",
        "\n",
        "\t\tif(3==len(image.shape) and 2==len(label.shape)):\n",
        "\t\t\tlabel = label[:,:,np.newaxis]\n",
        "\t\telif(2==len(image.shape) and 2==len(label.shape)):\n",
        "\t\t\timage = image[:,:,np.newaxis]\n",
        "\t\t\tlabel = label[:,:,np.newaxis]\n",
        "\n",
        "\t\tsample = {'imidx':imidx, 'image':image, 'label':label}\n",
        "\n",
        "\t\tif self.transform:\n",
        "\t\t\tsample = self.transform(sample)\n",
        "\n",
        "\t\treturn sample\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRjXYffF2hzr"
      },
      "source": [
        "# model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class REBNCONV(nn.Module):\n",
        "    def __init__(self,in_ch=3,out_ch=3,dirate=1):\n",
        "        super(REBNCONV,self).__init__()\n",
        "\n",
        "        self.conv_s1 = nn.Conv2d(in_ch,out_ch,3,padding=1*dirate,dilation=1*dirate)\n",
        "        self.bn_s1 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu_s1 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "        xout = self.relu_s1(self.bn_s1(self.conv_s1(hx)))\n",
        "\n",
        "        return xout\n",
        "\n",
        "## upsample tensor 'src' to have the same spatial size with tensor 'tar'\n",
        "def _upsample_like(src,tar):\n",
        "\n",
        "    src = F.upsample(src,size=tar.shape[2:],mode='bilinear')\n",
        "\n",
        "    return src\n",
        "\n",
        "\n",
        "### RSU-7 ###\n",
        "class RSU7(nn.Module):#UNet07DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU7,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool5 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv7 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv6d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "        hx = self.pool5(hx5)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx)\n",
        "\n",
        "        hx7 = self.rebnconv7(hx6)\n",
        "\n",
        "        hx6d =  self.rebnconv6d(torch.cat((hx7,hx6),1))\n",
        "        hx6dup = _upsample_like(hx6d,hx5)\n",
        "\n",
        "        hx5d =  self.rebnconv5d(torch.cat((hx6dup,hx5),1))\n",
        "        hx5dup = _upsample_like(hx5d,hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = _upsample_like(hx4d,hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = _upsample_like(hx3d,hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = _upsample_like(hx2d,hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-6 ###\n",
        "class RSU6(nn.Module):#UNet06DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU6,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx5)\n",
        "\n",
        "\n",
        "        hx5d =  self.rebnconv5d(torch.cat((hx6,hx5),1))\n",
        "        hx5dup = _upsample_like(hx5d,hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = _upsample_like(hx4d,hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = _upsample_like(hx3d,hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = _upsample_like(hx2d,hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-5 ###\n",
        "class RSU5(nn.Module):#UNet05DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU5,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5,hx4),1))\n",
        "        hx4dup = _upsample_like(hx4d,hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = _upsample_like(hx3d,hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = _upsample_like(hx2d,hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-4 ###\n",
        "class RSU4(nn.Module):#UNet04DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
        "        hx3dup = _upsample_like(hx3d,hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = _upsample_like(hx2d,hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-4F ###\n",
        "class RSU4F(nn.Module):#UNet04FRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4F,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=4)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=8)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=4)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=2)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx2 = self.rebnconv2(hx1)\n",
        "        hx3 = self.rebnconv3(hx2)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3d,hx2),1))\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2d,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "##### U^2-Net ####\n",
        "class U2NET(nn.Module):\n",
        "\n",
        "    def __init__(self,in_ch=3,out_ch=1):\n",
        "        super(U2NET,self).__init__()\n",
        "\n",
        "        self.stage1 = RSU7(in_ch,32,64)\n",
        "        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage2 = RSU6(64,32,128)\n",
        "        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage3 = RSU5(128,64,256)\n",
        "        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage4 = RSU4(256,128,512)\n",
        "        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage5 = RSU4F(512,256,512)\n",
        "        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage6 = RSU4F(512,256,512)\n",
        "\n",
        "        # decoder\n",
        "        self.stage5d = RSU4F(1024,256,512)\n",
        "        self.stage4d = RSU4(1024,128,256)\n",
        "        self.stage3d = RSU5(512,64,128)\n",
        "        self.stage2d = RSU6(256,32,64)\n",
        "        self.stage1d = RSU7(128,16,64)\n",
        "\n",
        "        self.side1 = nn.Conv2d(64,out_ch,3,padding=1)\n",
        "        self.side2 = nn.Conv2d(64,out_ch,3,padding=1)\n",
        "        self.side3 = nn.Conv2d(128,out_ch,3,padding=1)\n",
        "        self.side4 = nn.Conv2d(256,out_ch,3,padding=1)\n",
        "        self.side5 = nn.Conv2d(512,out_ch,3,padding=1)\n",
        "        self.side6 = nn.Conv2d(512,out_ch,3,padding=1)\n",
        "\n",
        "        self.outconv = nn.Conv2d(6,out_ch,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        #stage 1\n",
        "        hx1 = self.stage1(hx)\n",
        "        hx = self.pool12(hx1)\n",
        "\n",
        "        #stage 2\n",
        "        hx2 = self.stage2(hx)\n",
        "        hx = self.pool23(hx2)\n",
        "\n",
        "        #stage 3\n",
        "        hx3 = self.stage3(hx)\n",
        "        hx = self.pool34(hx3)\n",
        "\n",
        "        #stage 4\n",
        "        hx4 = self.stage4(hx)\n",
        "        hx = self.pool45(hx4)\n",
        "\n",
        "        #stage 5\n",
        "        hx5 = self.stage5(hx)\n",
        "        hx = self.pool56(hx5)\n",
        "\n",
        "        #stage 6\n",
        "        hx6 = self.stage6(hx)\n",
        "        hx6up = _upsample_like(hx6,hx5)\n",
        "\n",
        "        #-------------------- decoder --------------------\n",
        "        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n",
        "        hx5dup = _upsample_like(hx5d,hx4)\n",
        "\n",
        "        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = _upsample_like(hx4d,hx3)\n",
        "\n",
        "        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = _upsample_like(hx3d,hx2)\n",
        "\n",
        "        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = _upsample_like(hx2d,hx1)\n",
        "\n",
        "        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "\n",
        "        #side output\n",
        "        d1 = self.side1(hx1d)\n",
        "\n",
        "        d2 = self.side2(hx2d)\n",
        "        d2 = _upsample_like(d2,d1)\n",
        "\n",
        "        d3 = self.side3(hx3d)\n",
        "        d3 = _upsample_like(d3,d1)\n",
        "\n",
        "        d4 = self.side4(hx4d)\n",
        "        d4 = _upsample_like(d4,d1)\n",
        "\n",
        "        d5 = self.side5(hx5d)\n",
        "        d5 = _upsample_like(d5,d1)\n",
        "\n",
        "        d6 = self.side6(hx6)\n",
        "        d6 = _upsample_like(d6,d1)\n",
        "\n",
        "        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n",
        "\n",
        "        return F.sigmoid(d0), F.sigmoid(d1), F.sigmoid(d2), F.sigmoid(d3), F.sigmoid(d4), F.sigmoid(d5), F.sigmoid(d6)\n",
        "\n",
        "### U^2-Net small ###\n",
        "class U2NETP(nn.Module):\n",
        "\n",
        "    def __init__(self,in_ch=3,out_ch=1):\n",
        "        super(U2NETP,self).__init__()\n",
        "\n",
        "        self.stage1 = RSU7(in_ch,16,64)\n",
        "        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage2 = RSU6(64,16,64)\n",
        "        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage3 = RSU5(64,16,64)\n",
        "        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage4 = RSU4(64,16,64)\n",
        "        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage5 = RSU4F(64,16,64)\n",
        "        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage6 = RSU4F(64,16,64)\n",
        "\n",
        "        # decoder\n",
        "        self.stage5d = RSU4F(128,16,64)\n",
        "        self.stage4d = RSU4(128,16,64)\n",
        "        self.stage3d = RSU5(128,16,64)\n",
        "        self.stage2d = RSU6(128,16,64)\n",
        "        self.stage1d = RSU7(128,16,64)\n",
        "\n",
        "        self.side1 = nn.Conv2d(64,out_ch,3,padding=1)\n",
        "        self.side2 = nn.Conv2d(64,out_ch,3,padding=1)\n",
        "        self.side3 = nn.Conv2d(64,out_ch,3,padding=1)\n",
        "        self.side4 = nn.Conv2d(64,out_ch,3,padding=1)\n",
        "        self.side5 = nn.Conv2d(64,out_ch,3,padding=1)\n",
        "        self.side6 = nn.Conv2d(64,out_ch,3,padding=1)\n",
        "\n",
        "        self.outconv = nn.Conv2d(6,out_ch,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        #stage 1\n",
        "        hx1 = self.stage1(hx)\n",
        "        hx = self.pool12(hx1)\n",
        "\n",
        "        #stage 2\n",
        "        hx2 = self.stage2(hx)\n",
        "        hx = self.pool23(hx2)\n",
        "\n",
        "        #stage 3\n",
        "        hx3 = self.stage3(hx)\n",
        "        hx = self.pool34(hx3)\n",
        "\n",
        "        #stage 4\n",
        "        hx4 = self.stage4(hx)\n",
        "        hx = self.pool45(hx4)\n",
        "\n",
        "        #stage 5\n",
        "        hx5 = self.stage5(hx)\n",
        "        hx = self.pool56(hx5)\n",
        "\n",
        "        #stage 6\n",
        "        hx6 = self.stage6(hx)\n",
        "        hx6up = _upsample_like(hx6,hx5)\n",
        "\n",
        "        #decoder\n",
        "        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n",
        "        hx5dup = _upsample_like(hx5d,hx4)\n",
        "\n",
        "        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = _upsample_like(hx4d,hx3)\n",
        "\n",
        "        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = _upsample_like(hx3d,hx2)\n",
        "\n",
        "        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = _upsample_like(hx2d,hx1)\n",
        "\n",
        "        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "\n",
        "        #side output\n",
        "        d1 = self.side1(hx1d)\n",
        "\n",
        "        d2 = self.side2(hx2d)\n",
        "        d2 = _upsample_like(d2,d1)\n",
        "\n",
        "        d3 = self.side3(hx3d)\n",
        "        d3 = _upsample_like(d3,d1)\n",
        "\n",
        "        d4 = self.side4(hx4d)\n",
        "        d4 = _upsample_like(d4,d1)\n",
        "\n",
        "        d5 = self.side5(hx5d)\n",
        "        d5 = _upsample_like(d5,d1)\n",
        "\n",
        "        d6 = self.side6(hx6)\n",
        "        d6 = _upsample_like(d6,d1)\n",
        "\n",
        "        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n",
        "\n",
        "        return F.sigmoid(d0), F.sigmoid(d1), F.sigmoid(d2), F.sigmoid(d3), F.sigmoid(d4), F.sigmoid(d5), F.sigmoid(d6)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ls_Mr_ss0e4"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image as Img\n",
        "from PIL import ImageOps\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from imutils import paths\n",
        "\n",
        "from skimage.transform import resize\n",
        "from skimage import io, transform\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    \"\"\"\n",
        "    Creates a model and return it.\n",
        "    \"\"\"\n",
        "    # --------- 3. model define ---------\n",
        "    # print(MODEL_NAME,MODEL_PATH)\n",
        "    MODEL_NAME = FILE_DICT[\"MODEL_NAME\"]\n",
        "    if MODEL_NAME == 'u2net': \n",
        "        # print(\"...Loading U2NET Model...\")\n",
        "        net = U2NET(3,1)\n",
        "    elif MODEL_NAME == 'u2netp':\n",
        "        # print(\"...Loading U2NETP Model...\")\n",
        "        net = U2NETP(3,1)    \n",
        "    if torch.cuda.is_available():\n",
        "        net.load_state_dict(torch.load(FILE_DICT[\"MODEL_PATH\"]))\n",
        "        net.cuda()\n",
        "    else:\n",
        "        # print('CPU')        \n",
        "        net.load_state_dict(torch.load(FILE_DICT[\"MODEL_PATH\"], map_location=torch.device('cpu')))\n",
        "\n",
        "    net.eval()\n",
        "    return net\n",
        "\n",
        "#-------Defining Utility Functions-----\n",
        "\n",
        "def utitlities():\n",
        "    \"\"\"\n",
        "    Creates the list of directories \n",
        "    Creates configuration files\n",
        "    Returns the dictionary of directories\n",
        "    \"\"\"\n",
        "    #Changing of model name from \"u2netp\" --> \"u2net\" \n",
        "    # must be based on the environment \n",
        "    MODEL_NAME = \"u2netp\"\n",
        "    FILE_DICT = {\n",
        "        \"HOME_PATH\" : '/content',\n",
        "        \"INPUT_DIRECTORY\" : '/content/images/',\n",
        "        \"CROPPED_PERSON_ONLY_OUTPUT\" : '/content/output/Cropped_person_only_output/',\n",
        "        \"BLACK_AND_WHITE_MASKING\" : '/content/output/Black_and_white_masking/',\n",
        "        \"MODEL_NAME\" : MODEL_NAME,\n",
        "        \"MODEL_PATH\" : f'/content/model_weights/{MODEL_NAME}.pth',\n",
        "        \"LOGS_DIR\" : \"/content/output/logs/\"\n",
        "    }\n",
        "    dir_to_make = [\n",
        "                   '/content/output/Cropped_person_only_output/',\n",
        "                   '/content/output/Black_and_white_masking/',\n",
        "                   \"/content/output/logs/\"\n",
        "                  ]\n",
        "    \n",
        "    for dir in dir_to_make:\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "\n",
        "\n",
        "    return FILE_DICT\n",
        "\n",
        "\n",
        "# normalize the predicted SOD probability map (SOD = Salient Object Detection)\n",
        "\n",
        "def normPRED(data):\n",
        "    maximum = torch.max(data)\n",
        "    minimun = torch.min(data)\n",
        "\n",
        "    dn = (data-minimun)/(maximum-minimun)\n",
        "\n",
        "    return dn\n",
        "\n",
        "\n",
        "def save_output(image_path,pred,desired_dir,image_name):\n",
        "\n",
        "    predict = pred.squeeze()\n",
        "    predict_np = predict.cpu().data.numpy()\n",
        "\n",
        "    im = Img.fromarray(predict_np*255).convert('RGB')\n",
        "    # img_name = image_name.split(os.sep)[-1]\n",
        "    image = io.imread(image_path)\n",
        "    resized_image = im.resize((image.shape[1],image.shape[0]),resample=Img.BILINEAR)\n",
        "\n",
        "    splitting = image_name.split(\".\")\n",
        "    resized_image.save(desired_dir + splitting[0]+'.png')\n",
        "\n",
        "\n",
        "def working(inp_name,inp_dir,COUNTING):\n",
        "\n",
        "    # define the cutoff threshold below which, background will be removed.\n",
        "    THRESHOLD = 0.7\n",
        "    # fuzzy threshold in percentage.\n",
        "    # it checks the fuzzyness of an image.\n",
        "    FUZZY_THRESHOLD = 10.0\n",
        "\n",
        "\n",
        "\n",
        "    inp_dir = os.path.join(FILE_DICT[\"INPUT_DIRECTORY\"],inp_dir)\n",
        "    image = Img.open(inp_dir)\n",
        "    image = ImageOps.exif_transpose(image)\n",
        "    image.save(inp_dir)\n",
        "    img_name_list = [os.path.join(FILE_DICT[\"INPUT_DIRECTORY\"],inp_name)]\n",
        "    # print(img_name_list)\n",
        "\n",
        "    test_salobj_dataset = SalObjDataset(img_name_list = img_name_list,\n",
        "                                        lbl_name_list = [],\n",
        "                                        transform=transforms.Compose([RescaleT(320),\n",
        "                                                                        ToTensorLab(flag=0)])\n",
        "                                        )\n",
        "    test_salobj_dataloader = DataLoader(test_salobj_dataset,\n",
        "                                        batch_size=1,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=0)\n",
        "\n",
        "    for i_test, data_test in enumerate(test_salobj_dataloader):\n",
        "\n",
        "        # print(\"inferencing:\",img_name_list[i_test].split(os.sep)[-1])\n",
        "\n",
        "        inputs_test = data_test['image']\n",
        "        inputs_test = inputs_test.type(torch.FloatTensor)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            inputs_test = Variable(inputs_test.cuda())\n",
        "        else:\n",
        "            inputs_test = Variable(inputs_test)\n",
        "\n",
        "        d1,d2,d3,d4,d5,d6,d7= net(inputs_test)\n",
        "\n",
        "        # normalization\n",
        "        pred = d1[:,0,:,:]\n",
        "        pred = normPRED(pred)\n",
        "        \n",
        "        # save results to test_results folder\n",
        "        save_output(img_name_list[i_test],pred,FILE_DICT[\"BLACK_AND_WHITE_MASKING\"],inp_name)\n",
        "\n",
        "        del d1,d2,d3,d4,d5,d6,d7\n",
        "\n",
        "\n",
        "    output = load_img(FILE_DICT[\"BLACK_AND_WHITE_MASKING\"]+inp_name[:-4]+'.png')\n",
        "\n",
        "    # convert output to numpy array and rescale(255 for RBG images)\n",
        "    RESCALE = 255\n",
        "    out_img = img_to_array(output)\n",
        "    out_img /= RESCALE\n",
        "\n",
        "\n",
        "    fuzzy = ((0 < out_img) & (out_img <= 0.7)).sum()\n",
        "    out_img_size = out_img.size\n",
        "    nonzero_count = np.count_nonzero(out_img)\n",
        "    fuzzy_percentage = (fuzzy/nonzero_count)*100\n",
        "\n",
        "    if fuzzy_percentage > FUZZY_THRESHOLD:\n",
        "        with open(FILE_DICT[\"LOGS_DIR\"]+\"unprocessed.txt\",\"a\") as txtfile:\n",
        "            txtfile.write(inp_name+\" \\n\")\n",
        "            COUNTING[1] += 1\n",
        "        return\n",
        "\n",
        "    # refine the output\n",
        "    # out_img[out_img > THRESHOLD] = 1\n",
        "    out_img[out_img <= THRESHOLD] = 0\n",
        "    #plt.imshow(out_img)\n",
        "\n",
        "    out_img = cv2.blur(out_img,(5,5))\n",
        "    out_img = cv2.GaussianBlur(out_img, (7,7),0)\n",
        "\n",
        "    shape = out_img.shape\n",
        "    a_layer_init = np.ones(shape = (shape[0],shape[1],1))\n",
        "    mul_layer = np.expand_dims(out_img[:,:,0],axis=2)\n",
        "    a_layer = mul_layer*a_layer_init\n",
        "    rgba_out = np.append(out_img,a_layer,axis=2)\n",
        "\n",
        "    input1 = load_img(FILE_DICT[\"INPUT_DIRECTORY\"]+inp_name)\n",
        "\n",
        "\n",
        "    inp_img = img_to_array(input1)\n",
        "    inp_img /= RESCALE\n",
        "\n",
        "    a_layer = np.ones(shape = (shape[0],shape[1],1))\n",
        "    rgba_inp = np.append(inp_img,a_layer,axis=2)\n",
        "\n",
        "    rem_back = (rgba_inp*rgba_out)\n",
        "    rem_back_scaled = Img.fromarray((rem_back*RESCALE).astype('uint8'), 'RGBA')\n",
        "    rem_back_scaled.save(FILE_DICT[\"CROPPED_PERSON_ONLY_OUTPUT\"]+inp_name[:-4]+\".png\")\n",
        "\n",
        "    with open(FILE_DICT[\"LOGS_DIR\"]+\"processed.txt\",\"a\") as txtfile:\n",
        "            txtfile.write(inp_name+\" \\n\")\n",
        "            COUNTING[0] += 1\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q089eul4wZrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "769b2fab-c5d5-42a2-86cf-7ab0e316da2c"
      },
      "source": [
        "counting = [0,0] #zeroth index for processed image 1st for unprocessed\n",
        "print(\"Starting the process...\")\n",
        "FILE_DICT = utitlities()\n",
        "print(\"Files created..\")\n",
        "print(\"Building the model\")\n",
        "net = build_model()\n",
        "print(\"Model is built.\")\n",
        "dataset_paths = os.listdir(FILE_DICT[\"INPUT_DIRECTORY\"])\n",
        "for imagepath in tqdm(dataset_paths):\n",
        "    specific_img_path = imagepath.split(os.path.sep)[0]\n",
        "    img_name = specific_img_path.split('/')\n",
        "    working(img_name[-1],specific_img_path,counting)\n",
        "print(\"Total Processed images are: \",counting[0])\n",
        "print(\"Total Unprocessed images are: \",counting[1])\n",
        "print('Finished..')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting the process...\n",
            "Files created..\n",
            "Building the model\n",
            "Model is built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 13/13 [00:42<00:00,  3.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total Processed images are:  1\n",
            "Total Unprocessed images are:  12\n",
            "Finished..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}